{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code prevents the kernel from stopping when XGBoost is running\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load in DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_with_gensim_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'Unnamed: 0.1.1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In the second season finale, back in 1991, the...</td>\n",
       "      <td>And never more so than in Showtime’s new serie...</td>\n",
       "      <td>['      And never more so than in Showtime’s n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>When speaking to DeepMind and Google developer...</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for humans — ...</td>\n",
       "      <td>['      AlphaGo’s victory isn’t a defeat for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive attack</td>\n",
       "      <td>How a weapon against war became a weapon...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>International visitors for the event are commo...</td>\n",
       "      <td>How a weapon against war became a weapon again...</td>\n",
       "      <td>['      How a weapon against war became a weap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brain drain</td>\n",
       "      <td>Genius quietly laid off a bunch of its e...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In a post on the Genius blog at the time, co-f...</td>\n",
       "      <td>Genius quietly laid off a bunch of its enginee...</td>\n",
       "      <td>['      Genius quietly laid off a bunch of its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook takes flight</td>\n",
       "      <td>Inside the test flight of Facebook’s fir...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>But if your goal is to stay in the air for a l...</td>\n",
       "      <td>Inside the test flight of Facebook’s first int...</td>\n",
       "      <td>['      Inside the test flight of Facebook’s f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1                                  AI, the humanity!   \n",
       "2                                     Massive attack   \n",
       "3                                        Brain drain   \n",
       "4                              Facebook takes flight   \n",
       "\n",
       "                                             content  category  \\\n",
       "0        And never more so than in Showtime’s new...  Longform   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  Longform   \n",
       "2        How a weapon against war became a weapon...  Longform   \n",
       "3        Genius quietly laid off a bunch of its e...  Longform   \n",
       "4        Inside the test flight of Facebook’s fir...  Longform   \n",
       "\n",
       "                                      gensim_summary  \\\n",
       "0  In the second season finale, back in 1991, the...   \n",
       "1  When speaking to DeepMind and Google developer...   \n",
       "2  International visitors for the event are commo...   \n",
       "3  In a post on the Genius blog at the time, co-f...   \n",
       "4  But if your goal is to stay in the air for a l...   \n",
       "\n",
       "                                           first_100  \\\n",
       "0  And never more so than in Showtime’s new serie...   \n",
       "1  AlphaGo’s victory isn’t a defeat for humans — ...   \n",
       "2  How a weapon against war became a weapon again...   \n",
       "3  Genius quietly laid off a bunch of its enginee...   \n",
       "4  Inside the test flight of Facebook’s first int...   \n",
       "\n",
       "                                      sent_tokenized  \n",
       "0  ['      And never more so than in Showtime’s n...  \n",
       "1  ['      AlphaGo’s victory isn’t a defeat for h...  \n",
       "2  ['      How a weapon against war became a weap...  \n",
       "3  ['      Genius quietly laid off a bunch of its...  \n",
       "4  ['      Inside the test flight of Facebook’s f...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check for null values & drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      And never more so than in Showtime’s new series revival Some spoilers ahead through episode 4 of season 3 of Twin Peaks. On May 21st, Showtime brought back David Lynch’s groundbreaking TV series Twin Peaks, and fulfilled a prophecy in the process. In the second season finale, back in 1991, the spirit of series-defining murder victim Laura Palmer told FBI special agent and series protagonist Dale Cooper, “I’ll see you again in 25 years.” That clip plays again in the first episode of Lynch’s Twin Peaks revival, as a reminder that decades have in fact gone by, Laura’s promise has been carried out, and a series canceled mid-story is back on the air.A lot has changed in 25 years. The original cast members, who are mostly back on board, have all aged heavily and visibly. Many of the characters have moved on in life, getting new jobs, forming families, or taking up new obsessions. But in the opening episode, Dale Cooper was still where the show left him in 1991: trapped in the spirit domain known as the Black Lodge, at the mercy of incomprehensible forces that behave in erratic, alien ways. In other words, he’s just like anyone who’s actually watching Twin Peaks. As the third season began, the audience was also stuck back in 1991, waiting to see whether we were going to move on from the show’s many long-gestating cliffhangers. And we were also at the mercy of the incomprehensible force that is David Lynch, with his erratic, alien storytelling methods.All protagonists are mediators who help tell audiences how to interpret the narrative around them, but Dale Cooper is something else entirely: he is the audience, stumbling through Lynch’s obscure vision, and mutating along with it. The show’s tone, budget, and format have all changed with the 2017 revival, and Cooper, too, has changed — more so than any other character on the show. But he’s changed in ways we should recognize. They’re the same ways we’ve changed, as Twin Peaks has progressed from era-defining hit to weird cable art-experiment. The old series followed Agent Cooper through the painful, awkward process of maturing as an agent and a man. And his development happened in parallel with the maturing of a TV audience that had to learn how to follow a new kind of story.All protagonists mediate their stories, but Dale Cooper is something else entirelyToday, viewers have more sophisticated expectations than they did in the 1990s. They expect long arcs, slow character development, and mysteries that may take hours of air time to explore, let alone to decode. But Showtime’s new series is still leaving viewers curious, frustrated, baffled, and without the tools to translate what they’re seeing — which is exactly what Agent Cooper seems to be feeling right now as well. Consider Cooper as he started Twin Peaks back in 1990, as a fresh-faced, perky outsider walking into a mid-sized mountain community with no idea what to expect. Like the audience, he was entranced by the town of Twin Peaks — its quirky people, its unexpected pleasures, the sheer vividness of everything around him. Yes, he was there to solve a murder, but he was endlessly confident about his ability to tackle any case. The audience felt the same natural confidence. We knew how TV murder mysteries went. We thought we knew exactly what to expect from that end of the story: some procedural details, some red herrings, some drama, and eventually a solution.                Image: ABC  But like Cooper, we were seduced and distracted by Twin Peaks’ unexpected pleasures, the way the town unfolded on-screen, with all its strange domestic soap opera dramas and oddball interactions. Like Coop, we found our fun in the unusual texture and color of the world David Lynch and Mark Frost built. In those early days, Twin Peaks was a popular fad — the two-hour pilot was the season’s highest-rated TV movie — and the popular way to appreciate it was by emulating Dale Cooper’s experience as much as possible. Lifestyle pieces proliferated in the media, tracking people who threw Peaks parties to watch the show while eating all the things Cooper rhapsodized about in the early episodes: stacks of doughnuts, cherry pie, coffee, and breakfast food. (“Nothing beats the taste sensation when maple syrup collides with ham!” he chirps in episode 4.) The audience didn’t just want to watch Cooper solving a mystery, they wanted to be him, experiencing his outsized cheer for the world.The audience didn’t just want to watch Cooper solving a mystery, they wanted to be himAs the story went on, though, the tone darkened. Cooper lost his Boy Scout enthusiasm for food and the smell of Douglas firs. As more details emerged in the Laura Palmer murder case, another victim surfaced, and the supernatural side of the story emerged, Twin Peaks stopped sending Cooper on wacky cosplay adventures to Canada, and letting him vet his clues with oddball psychic experiments. It started confronting him with unexpected, alarming experiences. He took the first one in stride: visiting the Black Lodge in a dream, he returned convinced that he’d solved the murder, and that all would be well once he remembered the solution. Like us, he didn’t really understand what was going on at that point of the story, but he was still optimistic, and still willing to roll with every strange new revelation. Then Cooper got shot. The second season of Twin Peaks opened with him bleeding on the ground, enduring the unhelpful attentions of “the world’s oldest waiter,” listening to a glowing giant who dispenses information without acknowledging that Cooper may not live to use it, and having a strained one-way conversation with his voice-activated tape recorder. The viewers suffered along with him, through excruciating events that seemed drawn out to the point of perversity. Suddenly, being Agent Dale Cooper wasn’t fun anymore. His confidence was punctured, and we were all baffled and helpless together.                Image: ABC  There are moments in season 2 where Cooper bounces back into form, but they’re outnumbered by events that exhaust and chasten him, visibly transforming him into a more solemn, internal man. Jean Renault held him hostage, beat him, and threatened to murder him, suggesting Cooper was the cause of the town’s growing darkness. His former FBI partner Windom Earle brought a new chaos to town, and revealed Cooper’s past failings. Cooper lost his FBI standing and his love interest. He saw Earle’s soul consumed in front of him. A murderous monster took his place in the outside world. By the time season 2 ended, the audience had seen Cooper frightened, powerless, and confused as much as it ever saw him confident and in control. He stopped being a motive force in the world, and became a passive object in his own story. The series’s cancellation left viewers just as rudderless and abandoned as he was.‘Twin Peaks’ was about a hero maturing, but also about how the world consumed and broke himCooper’s trend toward impotence over the course of Twin Peaks’ original series run made for an ambitious and personal story. In the 1990s, TV viewers weren’t used to long-arc serial dramas where the protagonist changed rapidly and irrevocably, the way protagonists are expected to in today’s stories. But while Twin Peaks’ arc was compelling to many of the fans who stuck with it, it was wearying and demoralizing as well. The ratings trended steadily and sharply downward, peaking at milestones — the second season premiere, the reveal of who killed Laura Palmer — but still plummeting from the early days. The ratings drop was a form of feedback from a viewership who, like Cooper, weren’t confident and eager anymore. They began rejecting the show as it rejected its early tone, and its early promise. As Twin Peaks developed, it became clear that it was about the maturing of a hero, but it was also about how the vast and incomprehensible aspects of his world claimed, consumed, and broke him. Viewers couldn’t be blamed for pulling away from that story.And as Lynch withdrew from the show, it became narratively muddled, inconsistent, and sometimes downright silly. Cooper’s story remains one relatively consistent throughline, but it’s a tragic one, in which a fan-favorite character, the voice and point of view of the series, loses his joy, his freedom, and his capacity to control his own life. And it became the story of an audience that flocked to the show for lively, quirky surprises, and wound up splintered, divided, and uncertain.                Image: Showtime  Showtime’s series launches with Agent Cooper as thoroughly broken as he’s ever been. The first two episodes find him still trapped in the Lodge, facing the shrieking spirit of Laura Palmer and an angry human-sized nervous system topped by a pulsing, talking brain. He’s ejected into space, threatened by an unseen force, and rescued by a blinded woman with unclear motives who helps him in unclear ways. Finally, he’s fed through an electrical socket into what seems to be a decoy body, living its own life until he takes it over. By episode 4 of the series, he’s stumbling around in a lobotomized daze, repeating whatever people say to him, bellowing “Help” at random strangers and “Helloooooo!” at slot machines. He’s confused, helpless, and only slowly regaining the tools he needs to function in this world.And so are we. The knowledge that Lynch has been given creative control of the show is a form of reassurance, a promise that even if the new Peaks narrative is baffling and bizarre, it’s at least intended. It’s not the work of slot-fillers trying to pad out an infinitely ongoing program it’s a creative mastermind trying to tell a specific story. But that story is once again leaving viewers at sea, trying to pick apart Lynch’s work for tiny clues about what they’re watching. We’re back in Dale Cooper’s position, wandering through a freshly revived world, and trying to catch up with the ways it’s moved on in his absence.                Image: Showtime  The problem with the new Peaks as of episode 4, though, is that we have so little basis for understanding who our audience avatar is right now. Is Cooper mentally impaired because he’s spent 25 years outside of time and space? Because he’s stuck in a false, constructed body? Because Bob claimed some part of him while stealing his identity? Or just because Lynch thinks it’s funny to have Kyle MacLachlan staggering around blank-faced, with a tie on his head and a dozen-word vocabulary? What are the stakes of the story at this point? What is the audience to make of a narrative shaped by a character who isn’t capable of anything but following orders, following glowing magical sigils, and repeating whatever he hears? Like us, Cooper seems to have virtually no way of interpreting what he’s seeing. For now, he’s just along for the ride.we have so little basis for understanding our audience avatarThere’s no reason to believe that old Agent Cooper will ever return to Twin Peaks. The brash, confident, charmingly oddball young man he was in 1990 is long gone, and with good reason, given what he’s been through. In the same sort of way, no revival could ever recapture what Twin Peaks meant to audiences in 1990, when it was all so new and fresh and strange, so unlike anything that had ever appeared on network television.But he’s still around in some form, still bouncing through the trials of a Lynchian world. What’s missing now is any sense that he can help us understand what those trials mean. 1990s Cooper was an active force in his own story. He helped us navigate his surroundings, and see them with humor and wonder. He claimed, perhaps wrongly, but still convincingly, that there was order somewhere in the chaos. It’s natural for us to want to return to a mode where he can actively participate in his own story, where he’s helping solve its mysteries, instead of acting as its biggest conundrum. But even with his humanity lost and his agency gone, he still represents us onscreen. Even when he’s free-floating through a haze of glass boxes and stop-motion nightmares, we’re still with him. We’re still all Agent Cooper, navigating the mystery, and waiting to see where this is all going.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             0\n",
       "content           0\n",
       "category          0\n",
       "gensim_summary    0\n",
       "first_100         0\n",
       "sent_tokenized    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84965, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder object\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 84965 entries, 0 to 97063\n",
      "Data columns (total 6 columns):\n",
      "title             84965 non-null object\n",
      "content           84965 non-null object\n",
      "category          84965 non-null object\n",
      "gensim_summary    84965 non-null object\n",
      "first_100         84965 non-null object\n",
      "sent_tokenized    84965 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the encoder to the pandas column\n",
    "le.fit(df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Book Reviews', 'Exclusive', 'Longform', 'Reports', 'broadcast', 'business', 'general', 'newspaper', 'radio', 'wire']\n"
     ]
    }
   ],
   "source": [
    "targets = list(le.classes_)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the fitted encoder to the pandas column\n",
    "le.transform(df['category']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.content\n",
    "y = df.category\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5535896429972538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinkrause/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Book Reviews       0.00      0.00      0.00         3\n",
      "   Exclusive       0.00      0.00      0.00        22\n",
      "    Longform       0.00      0.00      0.00         3\n",
      "     Reports       0.00      0.00      0.00       194\n",
      "   broadcast       0.00      0.00      0.00      1590\n",
      "    business       0.00      0.00      0.00       193\n",
      "     general       0.97      0.02      0.04      5618\n",
      "   newspaper       0.54      1.00      0.70     13533\n",
      "       radio       0.00      0.00      0.00      1681\n",
      "        wire       1.00      0.18      0.30      2653\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     25490\n",
      "   macro avg       0.25      0.12      0.10     25490\n",
      "weighted avg       0.61      0.55      0.41     25490\n",
      "\n",
      "CPU times: user 30.4 s, sys: 748 ms, total: 31.1 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names = targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinkrause/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/austinkrause/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8925853275794429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Book Reviews       0.00      0.00      0.00         3\n",
      "   Exclusive       0.00      0.00      0.00        22\n",
      "    Longform       0.00      0.00      0.00         3\n",
      "     Reports       0.77      0.53      0.63       194\n",
      "   broadcast       0.85      0.73      0.78      1590\n",
      "    business       0.84      0.51      0.63       193\n",
      "     general       0.85      0.87      0.86      5618\n",
      "   newspaper       0.91      0.94      0.92     13533\n",
      "       radio       0.79      0.67      0.73      1681\n",
      "        wire       1.00      1.00      1.00      2653\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     25490\n",
      "   macro avg       0.60      0.52      0.56     25490\n",
      "weighted avg       0.89      0.89      0.89     25490\n",
      "\n",
      "CPU times: user 32.4 s, sys: 811 ms, total: 33.2 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)  \n",
    "# text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up paramaters dictionary for grid search\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200,300],\n",
    "    'max_features': ['auto',0.25, 0.33, 0.5],\n",
    "    'max_depth' : [None,5,6,7,8],\n",
    "    'min_samples_leaf': [0.03,0.04,0.05, 1, 2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of gridsearchCV\n",
    "#use params from above\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-bc79709465d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV_rfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               ])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', CV_rfc),\n",
    "              ])\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check best paramaters from the grid search\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use model to predict on test set\n",
    "rfc_pred = CV_rfc.best_estimator_.predict(X_test)\n",
    "#check accuracy on test set\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, rfc_pred))\n",
    "#check F1 of test set\n",
    "print('Test F1 score: ', f1_score(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix of random forest using SMOTE oversampling\n",
    "cnf_matrix_rf_smote_CV = confusion_matrix(y_test, rfc_pred)\n",
    "print('Confusion Matrix:\\n',cnf_matrix_rf_smote_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'rfc_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', XGBClassifier()),\n",
    "              ])\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8858768144370341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinkrause/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Book Reviews       0.00      0.00      0.00         3\n",
      "   Exclusive       0.00      0.00      0.00        22\n",
      "    Longform       0.00      0.00      0.00         3\n",
      "     Reports       0.82      0.48      0.61       194\n",
      "   broadcast       0.86      0.91      0.88      1590\n",
      "    business       0.92      0.64      0.76       193\n",
      "     general       0.94      0.74      0.83      5618\n",
      "   newspaper       0.86      0.97      0.91     13533\n",
      "       radio       0.82      0.63      0.71      1681\n",
      "        wire       1.00      1.00      1.00      2653\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     25490\n",
      "   macro avg       0.62      0.54      0.57     25490\n",
      "weighted avg       0.89      0.89      0.88     25490\n",
      "\n",
      "CPU times: user 37.9 s, sys: 1.64 s, total: 39.6 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'xgboost_model.sav'\n",
    "pickle.dump(xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KERAS NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X = df.content\n",
    "y = df.category\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the unique words in the vocab\n",
    "max_words = 1000\n",
    "\n",
    "#limit the vocab to the top words (max_words)\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n",
    "#creates a word index lookup of the vocab\n",
    "tokenize.fit_on_texts(X_train) # only fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrix to pass into the neural network\n",
    "x_train = tokenize.texts_to_matrix(X_train)\n",
    "x_test = tokenize.texts_to_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode labels and fit to training\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "\n",
    "#transform labels\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53527 samples, validate on 5948 samples\n",
      "Epoch 1/10\n",
      "53527/53527 [==============================] - 19s 351us/step - loss: 0.4497 - acc: 0.8268 - val_loss: 0.3107 - val_acc: 0.8790\n",
      "Epoch 2/10\n",
      "53527/53527 [==============================] - 18s 341us/step - loss: 0.2993 - acc: 0.8837 - val_loss: 0.2767 - val_acc: 0.8909\n",
      "Epoch 3/10\n",
      "53527/53527 [==============================] - 18s 338us/step - loss: 0.2480 - acc: 0.9026 - val_loss: 0.2535 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "53527/53527 [==============================] - 18s 342us/step - loss: 0.2091 - acc: 0.9189 - val_loss: 0.2499 - val_acc: 0.9055\n",
      "Epoch 5/10\n",
      "53527/53527 [==============================] - 18s 342us/step - loss: 0.1813 - acc: 0.9296 - val_loss: 0.2492 - val_acc: 0.9055\n",
      "Epoch 6/10\n",
      "53527/53527 [==============================] - 19s 347us/step - loss: 0.1529 - acc: 0.9400 - val_loss: 0.2476 - val_acc: 0.9114\n",
      "Epoch 7/10\n",
      "53527/53527 [==============================] - 19s 349us/step - loss: 0.1327 - acc: 0.9496 - val_loss: 0.2566 - val_acc: 0.9138\n",
      "Epoch 8/10\n",
      "53527/53527 [==============================] - 19s 349us/step - loss: 0.1107 - acc: 0.9581 - val_loss: 0.2569 - val_acc: 0.9126\n",
      "Epoch 9/10\n",
      "53527/53527 [==============================] - 19s 350us/step - loss: 0.1036 - acc: 0.9604 - val_loss: 0.2563 - val_acc: 0.9159\n",
      "Epoch 10/10\n",
      "53527/53527 [==============================] - 19s 354us/step - loss: 0.0896 - acc: 0.9659 - val_loss: 0.2742 - val_acc: 0.9171\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25490/25490 [==============================] - 2s 84us/step\n",
      "Test accuracy: 0.9176539819396772\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2788812780559133, 0.9176539819396772]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'keras_model.sav'\n",
    "pickle.dump(history, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
