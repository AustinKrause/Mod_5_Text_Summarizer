{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/austinkrause/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_with_gensim_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'Unnamed: 0.1.1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In the second season finale, back in 1991, the...</td>\n",
       "      <td>And never more so than in Showtime’s new serie...</td>\n",
       "      <td>['      And never more so than in Showtime’s n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>When speaking to DeepMind and Google developer...</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for humans — ...</td>\n",
       "      <td>['      AlphaGo’s victory isn’t a defeat for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive attack</td>\n",
       "      <td>How a weapon against war became a weapon...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>International visitors for the event are commo...</td>\n",
       "      <td>How a weapon against war became a weapon again...</td>\n",
       "      <td>['      How a weapon against war became a weap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brain drain</td>\n",
       "      <td>Genius quietly laid off a bunch of its e...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In a post on the Genius blog at the time, co-f...</td>\n",
       "      <td>Genius quietly laid off a bunch of its enginee...</td>\n",
       "      <td>['      Genius quietly laid off a bunch of its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook takes flight</td>\n",
       "      <td>Inside the test flight of Facebook’s fir...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>But if your goal is to stay in the air for a l...</td>\n",
       "      <td>Inside the test flight of Facebook’s first int...</td>\n",
       "      <td>['      Inside the test flight of Facebook’s f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1                                  AI, the humanity!   \n",
       "2                                     Massive attack   \n",
       "3                                        Brain drain   \n",
       "4                              Facebook takes flight   \n",
       "\n",
       "                                             content  category  \\\n",
       "0        And never more so than in Showtime’s new...  Longform   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  Longform   \n",
       "2        How a weapon against war became a weapon...  Longform   \n",
       "3        Genius quietly laid off a bunch of its e...  Longform   \n",
       "4        Inside the test flight of Facebook’s fir...  Longform   \n",
       "\n",
       "                                      gensim_summary  \\\n",
       "0  In the second season finale, back in 1991, the...   \n",
       "1  When speaking to DeepMind and Google developer...   \n",
       "2  International visitors for the event are commo...   \n",
       "3  In a post on the Genius blog at the time, co-f...   \n",
       "4  But if your goal is to stay in the air for a l...   \n",
       "\n",
       "                                           first_100  \\\n",
       "0  And never more so than in Showtime’s new serie...   \n",
       "1  AlphaGo’s victory isn’t a defeat for humans — ...   \n",
       "2  How a weapon against war became a weapon again...   \n",
       "3  Genius quietly laid off a bunch of its enginee...   \n",
       "4  Inside the test flight of Facebook’s first int...   \n",
       "\n",
       "                                      sent_tokenized  \n",
       "0  ['      And never more so than in Showtime’s n...  \n",
       "1  ['      AlphaGo’s victory isn’t a defeat for h...  \n",
       "2  ['      How a weapon against war became a weap...  \n",
       "3  ['      Genius quietly laid off a bunch of its...  \n",
       "4  ['      Inside the test flight of Facebook’s f...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df.title.tolist()\n",
    "summaries = df.gensim_summary.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "true_k = 4\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clusters = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a84a5af28>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=pred_clusters, s=10)\n",
    "terms = vectorizer.get_feature_names()\n",
    "plt.scatter(order_centroids[:, 0], order_centroids[:, 1], c='black', s=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_article_sents(tokenized_sentences):\n",
    "    document = tokenized_sentences\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(document)\n",
    "    cluster sentences\n",
    "    true_k = len(document)**.5\n",
    "    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "    model.fit(X)\n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    #plt.scatter(X[:, 0], X[:, 1], c=pred_clusters, s=10)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    plt.scatter(order_centroids[:, 0], order_centroids[:, 1], c='black', s=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a1218eaf8a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster_article_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-2f3bc946a860>\u001b[0m in \u001b[0;36mcluster_article_sents\u001b[0;34m(tokenized_sentences)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrue_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     order_centroids = model.cluster_centers_.argsort()[:, ::-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     #plt.scatter(X[:, 0], X[:, 1], c=pred_clusters, s=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 random_state=random_state)\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;31m# init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     centers = _init_centroids(X, n_clusters, init, random_state=random_state,\n\u001b[0;32m--> 531\u001b[0;31m                               x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialization complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_init_centroids\u001b[0;34m(X, k, init, random_state, x_squared_norms, init_size)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         centers = _k_init(X, k, random_state=random_state,\n\u001b[0;32m--> 748\u001b[0;31m                           x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    749\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_k_init\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mx_squared_norms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x_squared_norms None in _k_init'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "cluster_article_sents(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"TEHRAN, Iran (AP) — Iran's foreign minister warned the U.S. on Monday that it \"cannot expect to stay safe\"\n",
    "after launching what he described as an economic war against Tehran, taking a hard-line stance amid a visit by Germany's \n",
    "top diplomat seeking to defuse tensions. A stern-faced Mohammad Javad Zarif offered a series of threats over the \n",
    "ongoing tensions gripping the Persian Gulf. The crisis takes root in President Donald Trump's decision over a year \n",
    "ago to withdraw America from Iran's 2015 nuclear deal with world powers. Trump also reinstated tough sanctions on \n",
    "Iran, targeting its oil sector. \"Mr. Trump himself has announced that the U.S. has launched an economic war against \n",
    "Iran,\" Zarif said. \"The only solution for reducing tensions in this region is stopping that economic war.\" \"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokenize_all(lst):\n",
    "    totalvocab_stemmed = []\n",
    "    totalvocab_tokenized = []\n",
    "    for i in lst:\n",
    "        allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "        totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "\n",
    "        allwords_tokenized = tokenize_only(i)\n",
    "        totalvocab_tokenized.extend(allwords_tokenized)\n",
    "    return totalvocab_stemmed, totalvocab_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_stemmed, total_vocab_tokenized = stem_tokenize_all(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7984855"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_vocab_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7984855"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_vocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7984855 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "#create new df with stemmed vocab as the index and tokenized words as column\n",
    "vocab_df = pd.DataFrame({'words': total_vocab_tokenized}, index = total_vocab_stemmed)\n",
    "print(str(vocab_df.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>finale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words\n",
       "in          in\n",
       "the        the\n",
       "second  second\n",
       "season  season\n",
       "final   finale"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinkrause/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97064, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time \n",
    "#fit the vectorizer to summaries\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(summaries) \n",
    "\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of features from the tf-idf matrix\n",
    "features = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'said']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-995064b16a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0;32m--> 905\u001b[0;31m                         dense_output=dense_output)\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \"\"\"\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    502\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m            indptr)\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#find cosine similarity \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
