{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/austinkrause/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in our xgb classification model\n",
    "xgb = pickle.load(open(\"xgboost_model.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "    facts = requests.get(url)\n",
    "    soup = BeautifulSoup(facts.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(url):\n",
    "    #url = input('Enter a url: \\n')\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    text = []\n",
    "    for i in soup.find_all('p'):\n",
    "        text.append(i.get_text())\n",
    "\n",
    "    full_text = ' '.join(text).replace('\\xa0', '')\n",
    "#     word_count_ = full_text.count(' ')\n",
    "#     gensim_summary = summarize(full_text, word_count = word_count_/10).strip('. ').replace('.\\n', '')\n",
    "    \n",
    "#     print('\\n Full Text:\\n', full_text, '\\n\\n')\n",
    "#     print('Extractive Summary: \\n', gensim_summary)\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_article_text('https://news.yahoo.com/cambodia-islands-under-threat-woman-trying-save-them-144633896.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stop words\n",
    "stops = list(set(stopwords.words('english'))) + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to remove stop words\n",
    "def remove_stops(text):\n",
    "    text_no_stops = []\n",
    "    for i in text:\n",
    "        i = i.lower()\n",
    "        if i not in stops:\n",
    "            if len(i) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                text_no_stops.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return text_no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    lemmatized = []\n",
    "    for word in text:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create helper function to stem each word in a list and concat the list\n",
    "def stem_list(lst):\n",
    "    stemmed_list = []\n",
    "    for i in lst:\n",
    "        stemmed_list.append(stemmer.stem(i))\n",
    "    stem_string = ' '.join(stemmed_list[:100])\n",
    "    return stem_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to perform lemmatization, stemming, and final preprocessing\n",
    "def xgb_text_prep(sample_text):\n",
    "    tokens = word_tokenize(str(sample_text), language = 'en')\n",
    "    no_stops = remove_stops(tokens)\n",
    "    stemmed = stem_list(no_stops)\n",
    "    #stemmed = stemmed.replace('\\\\n', '')\n",
    "    return [stemmed]\n",
    "    #return no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand market stall line narrow concret path serv island main arteri offer usual assort good found across rural cambodia cheap noodl stack coca-cola bottl fake soccer jersey household clean product plastic bag carri home.. litter floor pile squeez sugarcan empti clam shell ocean plastic wrapper bottl cup straw empti bag swept way sight stark remind challeng resid koh sdach island surround archipelago face live harmoni environment.. five minut boat ride mainland cambodia koh sdach surround clear blue water sustain fish commun gener decad overfish indiscrimin wast dispos taken steep toll environment.. recommend eat half-truth teller aliv mariann williamson take trump']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_text_prep(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for xgboost prdiction\n",
    "def get_xgb_prediction(text):\n",
    "    preprocess = text_prep([text])\n",
    "    return xgb.predict(preprocess)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cosine similarities between sentences\n",
    "def find_similarities(text):\n",
    "    #tokenize sentences\n",
    "    sentences = sent_tokenize(text, language = 'en')\n",
    "    \n",
    "    #vectorize sentences\n",
    "    vectorizer = TfidfVectorizer(stop_words = stops)\n",
    "    trsfm=vectorizer.fit_transform(sentences)\n",
    "    #creat df for article\n",
    "    text_df = pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names(),index=sentences)\n",
    "    \n",
    "    #declare how many sentences to use in summary\n",
    "    num_sentences = text_df.shape[0]\n",
    "    num_summary_sentences = int(np.ceil(num_sentences**.5))\n",
    "        \n",
    "    #find cosine similarity for all sentences\n",
    "    similarities = cosine_similarity(trsfm, trsfm)\n",
    "    #print(similarities)\n",
    "    #create list to hold avg cosine similarities for each sentence\n",
    "    avgs = []\n",
    "    for i in similarities:\n",
    "        avgs.append(i.mean())\n",
    "     \n",
    "    #find index values of the sentences to be used for summary\n",
    "    top_idx = np.argsort(avgs)[-num_summary_sentences:]\n",
    "    \n",
    "    return top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_summary(text):\n",
    "    sents_for_sum = find_similarities(text)\n",
    "    sort = sorted(sents_for_sum)\n",
    "    print('\\n Sentences selected:', sort)\n",
    "    \n",
    "    sent_list = sent_tokenize(text)\n",
    "    print('\\n Total sentences:', len(sent_list))\n",
    "    \n",
    "    sents = []\n",
    "    for i in sort:\n",
    "        sents.append(sent_list[i].replace('\\n', ''))\n",
    "    \n",
    "    summary = ' '.join(sents)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentences selected: [1, 6, 10, 11, 22, 24, 43]\n",
      "\n",
      " Total sentences: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Swept out of the way, but not out of sight, it’s a stark reminder of the challenges residents of Koh Sdach island and the surrounding archipelago face in living harmoniously with their environment.. Just a five minute boat ride from mainland Cambodia, Koh Sdach is surrounded by clear blue waters that have sustained fishing communities for generations. But the plastic problem in these island communities is not just environmental. That doesn’t dissuade Oeun Sina, the loudest voice calling for better environmental practices on land and sea.. As deputy village chief on the island, Ms. Oeun Sina is trying to usher in a sea change in the way the 3,000 residents of her small fishing village see their island and the waters that surround it. She has taken it upon herself to educate her neighbors about recycling and trash disposal, and joins otherwise all-male community sea patrols in search of illegal fishing.. “I want my community to understand about plastics and not to fish illegally,” she says, sitting outside her house, as her three grandchildren play at her feet. Such price differences mean that there is no market in remote areas for plastic collection, explains Commune Chief Sok Chay.. “People here just throw everything away as there is no way to sell the plastic,” he says.. Old fishing nets full of empty beer and soft drink cans are common across the island.His response has been to instigate regular community cleanup days.. “Experts have told me that the plastic in the water is bad for our health, as the fish eat it and then we eat the fish. Some 30 students and 30 government people come to collect litter, plus a few people from the village,” he says.. Mr. Sok Chay sees no solution to the problem of waste and recycling other than burning waste. There will also be a focus on supporting the communities with their plastic and waste management problems.. For Mr. Sok Chay, the growing interest from the community and government in the long-term protection of the local environment is a source of pride.. “I am optimistic for the future.'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_summary(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_and_summary():\n",
    "    url = input('Enter a url: \\n')\n",
    "    text = get_article_text(url)\n",
    "    print('\\n')\n",
    "    xgb_preprocess = xgb_text_prep(text)\n",
    "    print('This article was placed into cluster:', xgb.predict(xgb_preprocess)[0])\n",
    "    \n",
    "    summary = build_summary(text)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ARTICLE 1 --- Supreme Court --- returns cluster 7\n",
    "https://news.yahoo.com/u-supreme-court-spurns-virginia-143413283.html;_ylt=AwrC0COK7wddIj8AGCPQtDMD;_ylu=X3oDMTEydGhybm9tBGNvbG8DYmYxBHBvcwMxBHZ0aWQDQjc2MDlfMQRzZWMDc3I-\n",
    "\n",
    "TEST ARTICLE 2 --- Donald Trump --- returns cluster 1\n",
    "https://news.yahoo.com/trump-says-d-foreigners-offer-233911079.html;_ylt=AwrC1C7Y8AddADIAoS_QtDMD;_ylu=X3oDMTEyaTE5czNyBGNvbG8DYmYxBHBvcwM0BHZ0aWQDQjc2MDlfMQRzZWMDc3I-\n",
    "\n",
    "TEST ARTICLE 3 --- Syria --- returns cluster 11\n",
    "https://news.yahoo.com/turkish-outpost-syria-shelled-syrian-080926968.html;_ylt=AwrC0wwt8gdd2WgAkwHQtDMD;_ylu=X3oDMTEydGhybm9tBGNvbG8DYmYxBHBvcwMxBHZ0aWQDQjc2MDlfMQRzZWMDc3I-\n",
    "\n",
    "TEST ARTICLE 4 --- Birth Control Health Insurance --- returns cluster 3\n",
    "https://news.yahoo.com/democrat-warren-wants-7-billion-134454649.html;_ylt=AwrC1DGZ8gddwlsAJwLQtDMD;_ylu=X3oDMTEydDBqZzZmBGNvbG8DYmYxBHBvcwMyBHZ0aWQDQjc2MDlfMQRzZWMDc3I-\n",
    "\n",
    "TEST ARTICLE 5 --- Bernie Sanders --- returns cluster 3\n",
    "https://news.yahoo.com/sanders-outline-democratic-socialism-means-045302693.html;_ylt=AwrC0CMD4whdTSoALAHQtDMD;_ylu=X3oDMTEydDBqZzZmBGNvbG8DYmYxBHBvcwMyBHZ0aWQDQjc2MDlfMQRzZWMDc3I-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a url: \n",
      "https://news.yahoo.com/democrat-warren-wants-7-billion-134454649.html;_ylt=AwrC1DGZ8gddwlsAJwLQtDMD;_ylu=X3oDMTEydDBqZzZmBGNvbG8DYmYxBHBvcwMyBHZ0aWQDQjc2MDlfMQRzZWMDc3I-\n",
      "\n",
      "\n",
      "This article was placed into cluster: 3\n",
      "\n",
      " Sentences selected: [0, 5, 7, 9]\n",
      "\n",
      " Total sentences: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'By Ginger Gibson WASHINGTON (Reuters) - Democratic presidential hopeful Elizabeth Warren is proposing creating a $7 billion fund to provide grants to help more minorities start their own business, she announced on Friday. The fund would provide grants - not loans or loan guarantees - to minority entrepreneurs, Warren is proposing. Warren would have the program administered by state and local governments. Additionally, Warren wants to require the states and local governments administering her program to hire more minority investment managers.'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_and_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
