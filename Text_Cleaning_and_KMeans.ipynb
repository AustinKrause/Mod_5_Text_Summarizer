{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk\n",
    "#pip install any packages you don't have\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_with_gensim_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In the second season finale, back in 1991, the...</td>\n",
       "      <td>And never more so than in Showtime’s new serie...</td>\n",
       "      <td>['      And never more so than in Showtime’s n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>When speaking to DeepMind and Google developer...</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for humans — ...</td>\n",
       "      <td>['      AlphaGo’s victory isn’t a defeat for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive attack</td>\n",
       "      <td>How a weapon against war became a weapon...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>International visitors for the event are commo...</td>\n",
       "      <td>How a weapon against war became a weapon again...</td>\n",
       "      <td>['      How a weapon against war became a weap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brain drain</td>\n",
       "      <td>Genius quietly laid off a bunch of its e...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In a post on the Genius blog at the time, co-f...</td>\n",
       "      <td>Genius quietly laid off a bunch of its enginee...</td>\n",
       "      <td>['      Genius quietly laid off a bunch of its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook takes flight</td>\n",
       "      <td>Inside the test flight of Facebook’s fir...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>But if your goal is to stay in the air for a l...</td>\n",
       "      <td>Inside the test flight of Facebook’s first int...</td>\n",
       "      <td>['      Inside the test flight of Facebook’s f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1                                  AI, the humanity!   \n",
       "2                                     Massive attack   \n",
       "3                                        Brain drain   \n",
       "4                              Facebook takes flight   \n",
       "\n",
       "                                             content  category  \\\n",
       "0        And never more so than in Showtime’s new...  Longform   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  Longform   \n",
       "2        How a weapon against war became a weapon...  Longform   \n",
       "3        Genius quietly laid off a bunch of its e...  Longform   \n",
       "4        Inside the test flight of Facebook’s fir...  Longform   \n",
       "\n",
       "                                      gensim_summary  \\\n",
       "0  In the second season finale, back in 1991, the...   \n",
       "1  When speaking to DeepMind and Google developer...   \n",
       "2  International visitors for the event are commo...   \n",
       "3  In a post on the Genius blog at the time, co-f...   \n",
       "4  But if your goal is to stay in the air for a l...   \n",
       "\n",
       "                                           first_100  \\\n",
       "0  And never more so than in Showtime’s new serie...   \n",
       "1  AlphaGo’s victory isn’t a defeat for humans — ...   \n",
       "2  How a weapon against war became a weapon again...   \n",
       "3  Genius quietly laid off a bunch of its enginee...   \n",
       "4  Inside the test flight of Facebook’s first int...   \n",
       "\n",
       "                                      sent_tokenized  \n",
       "0  ['      And never more so than in Showtime’s n...  \n",
       "1  ['      AlphaGo’s victory isn’t a defeat for h...  \n",
       "2  ['      How a weapon against war became a weap...  \n",
       "3  ['      Genius quietly laid off a bunch of its...  \n",
       "4  ['      Inside the test flight of Facebook’s f...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_100 = df.first_100.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_first_100'] = df.first_100.apply(lambda x: word_tokenize(x, language = 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "      <th>tokenized_first_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In the second season finale, back in 1991, the...</td>\n",
       "      <td>and never more so than in showtime’s new serie...</td>\n",
       "      <td>['      And never more so than in Showtime’s n...</td>\n",
       "      <td>[and, never, more, so, than, in, showtime, ’, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>When speaking to DeepMind and Google developer...</td>\n",
       "      <td>alphago’s victory isn’t a defeat for humans — ...</td>\n",
       "      <td>['      AlphaGo’s victory isn’t a defeat for h...</td>\n",
       "      <td>[alphago, ’, s, victory, isn, ’, t, a, defeat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive attack</td>\n",
       "      <td>How a weapon against war became a weapon...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>International visitors for the event are commo...</td>\n",
       "      <td>how a weapon against war became a weapon again...</td>\n",
       "      <td>['      How a weapon against war became a weap...</td>\n",
       "      <td>[how, a, weapon, against, war, became, a, weap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brain drain</td>\n",
       "      <td>Genius quietly laid off a bunch of its e...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In a post on the Genius blog at the time, co-f...</td>\n",
       "      <td>genius quietly laid off a bunch of its enginee...</td>\n",
       "      <td>['      Genius quietly laid off a bunch of its...</td>\n",
       "      <td>[genius, quietly, laid, off, a, bunch, of, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook takes flight</td>\n",
       "      <td>Inside the test flight of Facebook’s fir...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>But if your goal is to stay in the air for a l...</td>\n",
       "      <td>inside the test flight of facebook’s first int...</td>\n",
       "      <td>['      Inside the test flight of Facebook’s f...</td>\n",
       "      <td>[inside, the, test, flight, of, facebook, ’, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1                                  AI, the humanity!   \n",
       "2                                     Massive attack   \n",
       "3                                        Brain drain   \n",
       "4                              Facebook takes flight   \n",
       "\n",
       "                                             content  category  \\\n",
       "0        And never more so than in Showtime’s new...  Longform   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  Longform   \n",
       "2        How a weapon against war became a weapon...  Longform   \n",
       "3        Genius quietly laid off a bunch of its e...  Longform   \n",
       "4        Inside the test flight of Facebook’s fir...  Longform   \n",
       "\n",
       "                                      gensim_summary  \\\n",
       "0  In the second season finale, back in 1991, the...   \n",
       "1  When speaking to DeepMind and Google developer...   \n",
       "2  International visitors for the event are commo...   \n",
       "3  In a post on the Genius blog at the time, co-f...   \n",
       "4  But if your goal is to stay in the air for a l...   \n",
       "\n",
       "                                           first_100  \\\n",
       "0  and never more so than in showtime’s new serie...   \n",
       "1  alphago’s victory isn’t a defeat for humans — ...   \n",
       "2  how a weapon against war became a weapon again...   \n",
       "3  genius quietly laid off a bunch of its enginee...   \n",
       "4  inside the test flight of facebook’s first int...   \n",
       "\n",
       "                                      sent_tokenized  \\\n",
       "0  ['      And never more so than in Showtime’s n...   \n",
       "1  ['      AlphaGo’s victory isn’t a defeat for h...   \n",
       "2  ['      How a weapon against war became a weap...   \n",
       "3  ['      Genius quietly laid off a bunch of its...   \n",
       "4  ['      Inside the test flight of Facebook’s f...   \n",
       "\n",
       "                                 tokenized_first_100  \n",
       "0  [and, never, more, so, than, in, showtime, ’, ...  \n",
       "1  [alphago, ’, s, victory, isn, ’, t, a, defeat,...  \n",
       "2  [how, a, weapon, against, war, became, a, weap...  \n",
       "3  [genius, quietly, laid, off, a, bunch, of, its...  \n",
       "4  [inside, the, test, flight, of, facebook, ’, s...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = list(set(stopwords.words('english'))) + list(punctuation) + ['s', \"'\", 't', 'and', '\"', 'a', 'or', '/', 'in',\n",
    "                                                                    'for', '&', '-', \"''\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stop words\n",
    "def remove_stops(text):\n",
    "    text_no_stops = []\n",
    "    for i in text:\n",
    "        if i not in stops:\n",
    "            if len(i) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                text_no_stops.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return text_no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_100_no_stops'] = df['tokenized_first_100'].apply(lambda x: remove_stops(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that it worked\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize WordNetLemmatizer class\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    lemmatized = []\n",
    "    for word in text:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatize_first_100'] = df['first_100_no_stops'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatize_first_100'] = df['lemmatize_first_100'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "      <th>tokenized_first_100</th>\n",
       "      <th>first_100_no_stops</th>\n",
       "      <th>lemmatize_first_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In the second season finale, back in 1991, the...</td>\n",
       "      <td>and never more so than in showtime’s new serie...</td>\n",
       "      <td>['      And never more so than in Showtime’s n...</td>\n",
       "      <td>[and, never, more, so, than, in, showtime, ’, ...</td>\n",
       "      <td>[never, showtime, new, series, revival, spoile...</td>\n",
       "      <td>never showtime new series revival spoiler ahea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>When speaking to DeepMind and Google developer...</td>\n",
       "      <td>alphago’s victory isn’t a defeat for humans — ...</td>\n",
       "      <td>['      AlphaGo’s victory isn’t a defeat for h...</td>\n",
       "      <td>[alphago, ’, s, victory, isn, ’, t, a, defeat,...</td>\n",
       "      <td>[alphago, victory, defeat, humans, opportunity...</td>\n",
       "      <td>alphago victory defeat human opportunity loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive attack</td>\n",
       "      <td>How a weapon against war became a weapon...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>International visitors for the event are commo...</td>\n",
       "      <td>how a weapon against war became a weapon again...</td>\n",
       "      <td>['      How a weapon against war became a weap...</td>\n",
       "      <td>[how, a, weapon, against, war, became, a, weap...</td>\n",
       "      <td>[weapon, war, became, weapon, web, every, year...</td>\n",
       "      <td>weapon war became weapon web every year artist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brain drain</td>\n",
       "      <td>Genius quietly laid off a bunch of its e...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In a post on the Genius blog at the time, co-f...</td>\n",
       "      <td>genius quietly laid off a bunch of its enginee...</td>\n",
       "      <td>['      Genius quietly laid off a bunch of its...</td>\n",
       "      <td>[genius, quietly, laid, off, a, bunch, of, its...</td>\n",
       "      <td>[genius, quietly, laid, bunch, engineers, surv...</td>\n",
       "      <td>genius quietly laid bunch engineer survive med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook takes flight</td>\n",
       "      <td>Inside the test flight of Facebook’s fir...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>But if your goal is to stay in the air for a l...</td>\n",
       "      <td>inside the test flight of facebook’s first int...</td>\n",
       "      <td>['      Inside the test flight of Facebook’s f...</td>\n",
       "      <td>[inside, the, test, flight, of, facebook, ’, s...</td>\n",
       "      <td>[inside, test, flight, facebook, first, intern...</td>\n",
       "      <td>inside test flight facebook first internet dro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1                                  AI, the humanity!   \n",
       "2                                     Massive attack   \n",
       "3                                        Brain drain   \n",
       "4                              Facebook takes flight   \n",
       "\n",
       "                                             content  category  \\\n",
       "0        And never more so than in Showtime’s new...  Longform   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  Longform   \n",
       "2        How a weapon against war became a weapon...  Longform   \n",
       "3        Genius quietly laid off a bunch of its e...  Longform   \n",
       "4        Inside the test flight of Facebook’s fir...  Longform   \n",
       "\n",
       "                                      gensim_summary  \\\n",
       "0  In the second season finale, back in 1991, the...   \n",
       "1  When speaking to DeepMind and Google developer...   \n",
       "2  International visitors for the event are commo...   \n",
       "3  In a post on the Genius blog at the time, co-f...   \n",
       "4  But if your goal is to stay in the air for a l...   \n",
       "\n",
       "                                           first_100  \\\n",
       "0  and never more so than in showtime’s new serie...   \n",
       "1  alphago’s victory isn’t a defeat for humans — ...   \n",
       "2  how a weapon against war became a weapon again...   \n",
       "3  genius quietly laid off a bunch of its enginee...   \n",
       "4  inside the test flight of facebook’s first int...   \n",
       "\n",
       "                                      sent_tokenized  \\\n",
       "0  ['      And never more so than in Showtime’s n...   \n",
       "1  ['      AlphaGo’s victory isn’t a defeat for h...   \n",
       "2  ['      How a weapon against war became a weap...   \n",
       "3  ['      Genius quietly laid off a bunch of its...   \n",
       "4  ['      Inside the test flight of Facebook’s f...   \n",
       "\n",
       "                                 tokenized_first_100  \\\n",
       "0  [and, never, more, so, than, in, showtime, ’, ...   \n",
       "1  [alphago, ’, s, victory, isn, ’, t, a, defeat,...   \n",
       "2  [how, a, weapon, against, war, became, a, weap...   \n",
       "3  [genius, quietly, laid, off, a, bunch, of, its...   \n",
       "4  [inside, the, test, flight, of, facebook, ’, s...   \n",
       "\n",
       "                                  first_100_no_stops  \\\n",
       "0  [never, showtime, new, series, revival, spoile...   \n",
       "1  [alphago, victory, defeat, humans, opportunity...   \n",
       "2  [weapon, war, became, weapon, web, every, year...   \n",
       "3  [genius, quietly, laid, bunch, engineers, surv...   \n",
       "4  [inside, test, flight, facebook, first, intern...   \n",
       "\n",
       "                                 lemmatize_first_100  \n",
       "0  never showtime new series revival spoiler ahea...  \n",
       "1  alphago victory defeat human opportunity loss ...  \n",
       "2  weapon war became weapon web every year artist...  \n",
       "3  genius quietly laid bunch engineer survive med...  \n",
       "4  inside test flight facebook first internet dro...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('df_with_lemmings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KMEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "      <th>tokenized_first_100</th>\n",
       "      <th>first_100_no_stops</th>\n",
       "      <th>lemmatize_first_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In the second season finale, back in 1991, the...</td>\n",
       "      <td>and never more so than in showtime’s new serie...</td>\n",
       "      <td>['      And never more so than in Showtime’s n...</td>\n",
       "      <td>[and, never, more, so, than, in, showtime, ’, ...</td>\n",
       "      <td>[never, showtime, new, series, revival, spoile...</td>\n",
       "      <td>never showtime new series revival spoiler ahea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>When speaking to DeepMind and Google developer...</td>\n",
       "      <td>alphago’s victory isn’t a defeat for humans — ...</td>\n",
       "      <td>['      AlphaGo’s victory isn’t a defeat for h...</td>\n",
       "      <td>[alphago, ’, s, victory, isn, ’, t, a, defeat,...</td>\n",
       "      <td>[alphago, victory, defeat, humans, opportunity...</td>\n",
       "      <td>alphago victory defeat human opportunity loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive attack</td>\n",
       "      <td>How a weapon against war became a weapon...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>International visitors for the event are commo...</td>\n",
       "      <td>how a weapon against war became a weapon again...</td>\n",
       "      <td>['      How a weapon against war became a weap...</td>\n",
       "      <td>[how, a, weapon, against, war, became, a, weap...</td>\n",
       "      <td>[weapon, war, became, weapon, web, every, year...</td>\n",
       "      <td>weapon war became weapon web every year artist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brain drain</td>\n",
       "      <td>Genius quietly laid off a bunch of its e...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>In a post on the Genius blog at the time, co-f...</td>\n",
       "      <td>genius quietly laid off a bunch of its enginee...</td>\n",
       "      <td>['      Genius quietly laid off a bunch of its...</td>\n",
       "      <td>[genius, quietly, laid, off, a, bunch, of, its...</td>\n",
       "      <td>[genius, quietly, laid, bunch, engineers, surv...</td>\n",
       "      <td>genius quietly laid bunch engineer survive med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook takes flight</td>\n",
       "      <td>Inside the test flight of Facebook’s fir...</td>\n",
       "      <td>Longform</td>\n",
       "      <td>But if your goal is to stay in the air for a l...</td>\n",
       "      <td>inside the test flight of facebook’s first int...</td>\n",
       "      <td>['      Inside the test flight of Facebook’s f...</td>\n",
       "      <td>[inside, the, test, flight, of, facebook, ’, s...</td>\n",
       "      <td>[inside, test, flight, facebook, first, intern...</td>\n",
       "      <td>inside test flight facebook first internet dro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1                                  AI, the humanity!   \n",
       "2                                     Massive attack   \n",
       "3                                        Brain drain   \n",
       "4                              Facebook takes flight   \n",
       "\n",
       "                                             content  category  \\\n",
       "0        And never more so than in Showtime’s new...  Longform   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  Longform   \n",
       "2        How a weapon against war became a weapon...  Longform   \n",
       "3        Genius quietly laid off a bunch of its e...  Longform   \n",
       "4        Inside the test flight of Facebook’s fir...  Longform   \n",
       "\n",
       "                                      gensim_summary  \\\n",
       "0  In the second season finale, back in 1991, the...   \n",
       "1  When speaking to DeepMind and Google developer...   \n",
       "2  International visitors for the event are commo...   \n",
       "3  In a post on the Genius blog at the time, co-f...   \n",
       "4  But if your goal is to stay in the air for a l...   \n",
       "\n",
       "                                           first_100  \\\n",
       "0  and never more so than in showtime’s new serie...   \n",
       "1  alphago’s victory isn’t a defeat for humans — ...   \n",
       "2  how a weapon against war became a weapon again...   \n",
       "3  genius quietly laid off a bunch of its enginee...   \n",
       "4  inside the test flight of facebook’s first int...   \n",
       "\n",
       "                                      sent_tokenized  \\\n",
       "0  ['      And never more so than in Showtime’s n...   \n",
       "1  ['      AlphaGo’s victory isn’t a defeat for h...   \n",
       "2  ['      How a weapon against war became a weap...   \n",
       "3  ['      Genius quietly laid off a bunch of its...   \n",
       "4  ['      Inside the test flight of Facebook’s f...   \n",
       "\n",
       "                                 tokenized_first_100  \\\n",
       "0  [and, never, more, so, than, in, showtime, ’, ...   \n",
       "1  [alphago, ’, s, victory, isn, ’, t, a, defeat,...   \n",
       "2  [how, a, weapon, against, war, became, a, weap...   \n",
       "3  [genius, quietly, laid, off, a, bunch, of, its...   \n",
       "4  [inside, the, test, flight, of, facebook, ’, s...   \n",
       "\n",
       "                                  first_100_no_stops  \\\n",
       "0  [never, showtime, new, series, revival, spoile...   \n",
       "1  [alphago, victory, defeat, humans, opportunity...   \n",
       "2  [weapon, war, became, weapon, web, every, year...   \n",
       "3  [genius, quietly, laid, bunch, engineers, surv...   \n",
       "4  [inside, test, flight, facebook, first, intern...   \n",
       "\n",
       "                                 lemmatize_first_100  \n",
       "0  never showtime new series revival spoiler ahea...  \n",
       "1  alphago victory defeat human opportunity loss ...  \n",
       "2  weapon war became weapon web every year artist...  \n",
       "3  genius quietly laid bunch engineer survive med...  \n",
       "4  inside test flight facebook first internet dro...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Detect languages of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['lemmatize_first_100'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>gensim_summary</th>\n",
       "      <th>first_100</th>\n",
       "      <th>sent_tokenized</th>\n",
       "      <th>tokenized_first_100</th>\n",
       "      <th>first_100_no_stops</th>\n",
       "      <th>lemmatize_first_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>97038</td>\n",
       "      <td>97038</td>\n",
       "      <td>84941</td>\n",
       "      <td>97038</td>\n",
       "      <td>97038</td>\n",
       "      <td>97038</td>\n",
       "      <td>97038</td>\n",
       "      <td>97038</td>\n",
       "      <td>97038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ko</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title  content  category  gensim_summary  first_100  sent_tokenized  \\\n",
       "language                                                                        \n",
       "en        97038    97038     84941           97038      97038           97038   \n",
       "es            4        4         2               4          4               4   \n",
       "fr           19       19        19              19         19              19   \n",
       "it            2        2         2               2          2               2   \n",
       "ko            1        1         1               1          1               1   \n",
       "\n",
       "          tokenized_first_100  first_100_no_stops  lemmatize_first_100  \n",
       "language                                                                \n",
       "en                      97038               97038                97038  \n",
       "es                          4                   4                    4  \n",
       "fr                         19                  19                   19  \n",
       "it                          2                   2                    2  \n",
       "ko                          1                   1                    1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('language').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that are not english\n",
    "df = df.loc[df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('df_english_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_english_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['words', 'word', 'running', 'ran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to stem each word in a list and concat the list\n",
    "def stem_list(lst):\n",
    "    stemmed_list = []\n",
    "    for i in lst:\n",
    "        stemmed_list.append(stemmer.stem(i))\n",
    "    stem_string = ' '.join(stemmed_list)\n",
    "    return stem_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list contained in string to a regular list so it can be stemmed\n",
    "df['stemmed'] = df[\"first_100_no_stops\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem words in list\n",
    "df['stemmed'] = df[\"stemmed\"].apply(lambda x: stem_list(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that it worked\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['stemmed'].str.contains(\"archiveteam.org contain\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95790, 12)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKPOINT --- SAVE TO CSV\n",
    "#df.to_csv('df_with_stems_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKPOINT --- RUN TO OPEN CSV IF STARTING WORK HERE\n",
    "#df = pd.read_csv('df_with_stems_final.csv')\n",
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['stemmed'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['never showtim new seri reviv spoiler ahead episod season twin peak may 21st showtim brought back david lynch groundbreak tv seri twin peak fulfil propheci process second season final back 1991 spirit series-defin murder victim laura palmer told fbi special agent seri protagonist dale cooper see 25 years. clip play first episod lynch twin peak reviv remind decad fact gone laura promis',\n",
       " 'alphago victori defeat human opportun loss human man succumb machin heard alphago latest exploit last week crush world best go player confirm artifici intellig master ancient chines board game may heard news deliv doomsday terms.ther certain melancholi ke jie capitul sure 19-year-old chines prodigi declar would never lose ai follow alphago earthshak victori lee se-dol last year see onstag last week nearli bent doubl',\n",
       " 'weapon war becam weapon web everi year artist technolog enthusiast meet linz austria ar electronica festiv meetup citi downtown locat danub river festiv eye toward futur someth burn man ted confer visitor navig scientif equip led light color instal intern visitor event common enough 1998 festiv featur unlik particip pentagon.that year member art group call electron disturb theater']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to vectorize strings and perform tf-idf transformation\n",
    "def vectorize_texts(list_of_strings):\n",
    "    print('Performing vectorization and TF/IDF transformation on texts...')\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(list_of_strings)\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf = transformer.fit_transform(X)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_texts(num_clusters, tfidf):\n",
    "    #perform kmeans clustering for range of clusters\n",
    "    print('Beginning KMeans Clustering, number of clusters = ', num_clusters, '\\n') \n",
    "    km = KMeans(n_clusters=num_clusters, max_iter = 100, verbose = 2, n_init = 1).fit(tfidf)\n",
    "    \n",
    "    \n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Run Clustering for range of K's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing vectorization and TF/IDF transformation on texts...\n"
     ]
    }
   ],
   "source": [
    "documents_vectorized = vectorize_texts(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  3 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 185417.149\n",
      "Iteration  1, inertia 94192.242\n",
      "Iteration  2, inertia 93981.211\n",
      "Iteration  3, inertia 93903.577\n",
      "Iteration  4, inertia 93877.059\n",
      "Iteration  5, inertia 93863.868\n",
      "Iteration  6, inertia 93857.832\n",
      "Iteration  7, inertia 93855.082\n",
      "Iteration  8, inertia 93853.527\n",
      "Iteration  9, inertia 93852.659\n",
      "Iteration 10, inertia 93852.199\n",
      "Iteration 11, inertia 93851.906\n",
      "Iteration 12, inertia 93851.712\n",
      "Iteration 13, inertia 93851.602\n",
      "Iteration 14, inertia 93851.532\n",
      "Iteration 15, inertia 93851.489\n",
      "Iteration 16, inertia 93851.446\n",
      "Iteration 17, inertia 93851.428\n",
      "Iteration 18, inertia 93851.416\n",
      "Iteration 19, inertia 93851.408\n",
      "Iteration 20, inertia 93851.403\n",
      "Iteration 21, inertia 93851.399\n",
      "Iteration 22, inertia 93851.397\n",
      "Iteration 23, inertia 93851.396\n",
      "Iteration 24, inertia 93851.395\n",
      "Iteration 25, inertia 93851.394\n",
      "Iteration 26, inertia 93851.394\n",
      "Iteration 27, inertia 93851.394\n",
      "Converged at iteration 27: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans3 = cluster_texts(3, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans3.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = documents_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = calinski_harabaz_score(test, kmeans3.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  4 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 185231.174\n",
      "Iteration  1, inertia 94194.112\n",
      "Iteration  2, inertia 93873.094\n",
      "Iteration  3, inertia 93802.144\n",
      "Iteration  4, inertia 93783.657\n",
      "Iteration  5, inertia 93764.486\n",
      "Iteration  6, inertia 93745.738\n",
      "Iteration  7, inertia 93737.436\n",
      "Iteration  8, inertia 93732.944\n",
      "Iteration  9, inertia 93730.129\n",
      "Iteration 10, inertia 93728.577\n",
      "Iteration 11, inertia 93727.789\n",
      "Iteration 12, inertia 93727.387\n",
      "Iteration 13, inertia 93727.173\n",
      "Iteration 14, inertia 93727.032\n",
      "Iteration 15, inertia 93726.940\n",
      "Iteration 16, inertia 93726.884\n",
      "Iteration 17, inertia 93726.849\n",
      "Iteration 18, inertia 93726.826\n",
      "Iteration 19, inertia 93726.802\n",
      "Iteration 20, inertia 93726.767\n",
      "Iteration 21, inertia 93726.751\n",
      "Iteration 22, inertia 93726.741\n",
      "Iteration 23, inertia 93726.726\n",
      "Iteration 24, inertia 93726.711\n",
      "Iteration 25, inertia 93726.700\n",
      "Iteration 26, inertia 93726.687\n",
      "Iteration 27, inertia 93726.668\n",
      "Iteration 28, inertia 93726.641\n",
      "Iteration 29, inertia 93726.612\n",
      "Iteration 30, inertia 93726.577\n",
      "Iteration 31, inertia 93726.527\n",
      "Iteration 32, inertia 93726.425\n",
      "Iteration 33, inertia 93726.012\n",
      "Iteration 34, inertia 93723.784\n",
      "Iteration 35, inertia 93720.811\n",
      "Iteration 36, inertia 93720.376\n",
      "Iteration 37, inertia 93720.244\n",
      "Iteration 38, inertia 93720.196\n",
      "Iteration 39, inertia 93720.168\n",
      "Iteration 40, inertia 93720.151\n",
      "Iteration 41, inertia 93720.141\n",
      "Iteration 42, inertia 93720.131\n",
      "Iteration 43, inertia 93720.127\n",
      "Iteration 44, inertia 93720.125\n",
      "Iteration 45, inertia 93720.123\n",
      "Iteration 46, inertia 93720.122\n",
      "Iteration 47, inertia 93720.122\n",
      "Iteration 48, inertia 93720.122\n",
      "Converged at iteration 48: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans4= cluster_texts(4, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  5 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 183811.131\n",
      "Iteration  1, inertia 94008.502\n",
      "Iteration  2, inertia 93776.893\n",
      "Iteration  3, inertia 93704.016\n",
      "Iteration  4, inertia 93676.194\n",
      "Iteration  5, inertia 93665.691\n",
      "Iteration  6, inertia 93660.893\n",
      "Iteration  7, inertia 93658.211\n",
      "Iteration  8, inertia 93656.282\n",
      "Iteration  9, inertia 93654.502\n",
      "Iteration 10, inertia 93652.973\n",
      "Iteration 11, inertia 93651.605\n",
      "Iteration 12, inertia 93649.618\n",
      "Iteration 13, inertia 93647.007\n",
      "Iteration 14, inertia 93642.592\n",
      "Iteration 15, inertia 93633.020\n",
      "Iteration 16, inertia 93618.593\n",
      "Iteration 17, inertia 93613.156\n",
      "Iteration 18, inertia 93611.727\n",
      "Iteration 19, inertia 93610.996\n",
      "Iteration 20, inertia 93610.551\n",
      "Iteration 21, inertia 93610.287\n",
      "Iteration 22, inertia 93610.109\n",
      "Iteration 23, inertia 93610.002\n",
      "Iteration 24, inertia 93609.933\n",
      "Iteration 25, inertia 93609.859\n",
      "Iteration 26, inertia 93609.822\n",
      "Iteration 27, inertia 93609.801\n",
      "Iteration 28, inertia 93609.779\n",
      "Iteration 29, inertia 93609.760\n",
      "Iteration 30, inertia 93609.745\n",
      "Iteration 31, inertia 93609.732\n",
      "Iteration 32, inertia 93609.720\n",
      "Iteration 33, inertia 93609.710\n",
      "Iteration 34, inertia 93609.704\n",
      "Iteration 35, inertia 93609.698\n",
      "Iteration 36, inertia 93609.695\n",
      "Iteration 37, inertia 93609.691\n",
      "Iteration 38, inertia 93609.688\n",
      "Iteration 39, inertia 93609.686\n",
      "Iteration 40, inertia 93609.684\n",
      "Iteration 41, inertia 93609.683\n",
      "Iteration 42, inertia 93609.683\n",
      "Iteration 43, inertia 93609.682\n",
      "Iteration 44, inertia 93609.681\n",
      "Iteration 45, inertia 93609.681\n",
      "Iteration 46, inertia 93609.681\n",
      "Converged at iteration 46: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans5= cluster_texts(5, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  6 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 183325.682\n",
      "Iteration  1, inertia 94032.954\n",
      "Iteration  2, inertia 93752.987\n",
      "Iteration  3, inertia 93623.834\n",
      "Iteration  4, inertia 93566.280\n",
      "Iteration  5, inertia 93534.085\n",
      "Iteration  6, inertia 93511.956\n",
      "Iteration  7, inertia 93494.591\n",
      "Iteration  8, inertia 93480.131\n",
      "Iteration  9, inertia 93471.371\n",
      "Iteration 10, inertia 93466.003\n",
      "Iteration 11, inertia 93461.113\n",
      "Iteration 12, inertia 93455.414\n",
      "Iteration 13, inertia 93449.723\n",
      "Iteration 14, inertia 93443.690\n",
      "Iteration 15, inertia 93429.701\n",
      "Iteration 16, inertia 93413.804\n",
      "Iteration 17, inertia 93410.184\n",
      "Iteration 18, inertia 93409.451\n",
      "Iteration 19, inertia 93409.208\n",
      "Iteration 20, inertia 93409.077\n",
      "Iteration 21, inertia 93409.017\n",
      "Iteration 22, inertia 93408.988\n",
      "Iteration 23, inertia 93408.975\n",
      "Iteration 24, inertia 93408.967\n",
      "Iteration 25, inertia 93408.962\n",
      "Iteration 26, inertia 93408.961\n",
      "Iteration 27, inertia 93408.960\n",
      "Iteration 28, inertia 93408.960\n",
      "Iteration 29, inertia 93408.960\n",
      "Iteration 30, inertia 93408.960\n",
      "Iteration 31, inertia 93408.959\n",
      "Iteration 32, inertia 93408.959\n",
      "Iteration 33, inertia 93408.959\n",
      "Converged at iteration 33: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans6= cluster_texts(6, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  7 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 183795.868\n",
      "Iteration  1, inertia 93909.600\n",
      "Iteration  2, inertia 93580.205\n",
      "Iteration  3, inertia 93499.381\n",
      "Iteration  4, inertia 93442.008\n",
      "Iteration  5, inertia 93390.921\n",
      "Iteration  6, inertia 93379.439\n",
      "Iteration  7, inertia 93371.263\n",
      "Iteration  8, inertia 93365.784\n",
      "Iteration  9, inertia 93362.429\n",
      "Iteration 10, inertia 93360.238\n",
      "Iteration 11, inertia 93358.306\n",
      "Iteration 12, inertia 93356.849\n",
      "Iteration 13, inertia 93354.689\n",
      "Iteration 14, inertia 93349.996\n",
      "Iteration 15, inertia 93342.676\n",
      "Iteration 16, inertia 93340.173\n",
      "Iteration 17, inertia 93339.125\n",
      "Iteration 18, inertia 93338.183\n",
      "Iteration 19, inertia 93337.216\n",
      "Iteration 20, inertia 93336.229\n",
      "Iteration 21, inertia 93335.405\n",
      "Iteration 22, inertia 93334.719\n",
      "Iteration 23, inertia 93334.134\n",
      "Iteration 24, inertia 93333.613\n",
      "Iteration 25, inertia 93333.116\n",
      "Iteration 26, inertia 93332.695\n",
      "Iteration 27, inertia 93332.330\n",
      "Iteration 28, inertia 93332.034\n",
      "Iteration 29, inertia 93331.818\n",
      "Iteration 30, inertia 93331.615\n",
      "Iteration 31, inertia 93331.473\n",
      "Iteration 32, inertia 93331.357\n",
      "Iteration 33, inertia 93331.277\n",
      "Iteration 34, inertia 93330.699\n",
      "Iteration 35, inertia 93330.612\n",
      "Iteration 36, inertia 93330.537\n",
      "Iteration 37, inertia 93330.467\n",
      "Iteration 38, inertia 93330.395\n",
      "Iteration 39, inertia 93330.334\n",
      "Iteration 40, inertia 93330.259\n",
      "Iteration 41, inertia 93330.209\n",
      "Iteration 42, inertia 93330.153\n",
      "Iteration 43, inertia 93330.072\n",
      "Iteration 44, inertia 93330.046\n",
      "Iteration 45, inertia 93330.029\n",
      "Iteration 46, inertia 93330.016\n",
      "Iteration 47, inertia 93330.007\n",
      "Iteration 48, inertia 93329.995\n",
      "Iteration 49, inertia 93329.986\n",
      "Iteration 50, inertia 93329.981\n",
      "Iteration 51, inertia 93329.978\n",
      "Iteration 52, inertia 93329.975\n",
      "Iteration 53, inertia 93329.975\n",
      "Iteration 54, inertia 93329.974\n",
      "Iteration 55, inertia 93329.974\n",
      "Iteration 56, inertia 93329.974\n",
      "Iteration 57, inertia 93329.973\n",
      "Iteration 58, inertia 93329.973\n",
      "Converged at iteration 58: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans7= cluster_texts(7, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  8 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 182019.619\n",
      "Iteration  1, inertia 93871.466\n",
      "Iteration  2, inertia 93542.235\n",
      "Iteration  3, inertia 93423.602\n",
      "Iteration  4, inertia 93353.860\n",
      "Iteration  5, inertia 93313.134\n",
      "Iteration  6, inertia 93291.406\n",
      "Iteration  7, inertia 93279.023\n",
      "Iteration  8, inertia 93270.781\n",
      "Iteration  9, inertia 93264.181\n",
      "Iteration 10, inertia 93258.200\n",
      "Iteration 11, inertia 93251.715\n",
      "Iteration 12, inertia 93246.635\n",
      "Iteration 13, inertia 93242.689\n",
      "Iteration 14, inertia 93239.442\n",
      "Iteration 15, inertia 93236.716\n",
      "Iteration 16, inertia 93234.270\n",
      "Iteration 17, inertia 93230.595\n",
      "Iteration 18, inertia 93224.534\n",
      "Iteration 19, inertia 93221.466\n",
      "Iteration 20, inertia 93220.512\n",
      "Iteration 21, inertia 93220.041\n",
      "Iteration 22, inertia 93219.685\n",
      "Iteration 23, inertia 93219.352\n",
      "Iteration 24, inertia 93219.043\n",
      "Iteration 25, inertia 93218.761\n",
      "Iteration 26, inertia 93218.416\n",
      "Iteration 27, inertia 93218.004\n",
      "Iteration 28, inertia 93217.464\n",
      "Iteration 29, inertia 93216.709\n",
      "Iteration 30, inertia 93215.813\n",
      "Iteration 31, inertia 93214.612\n",
      "Iteration 32, inertia 93212.941\n",
      "Iteration 33, inertia 93210.616\n",
      "Iteration 34, inertia 93208.004\n",
      "Iteration 35, inertia 93205.196\n",
      "Iteration 36, inertia 93203.335\n",
      "Iteration 37, inertia 93202.605\n",
      "Iteration 38, inertia 93202.334\n",
      "Iteration 39, inertia 93202.192\n",
      "Iteration 40, inertia 93202.106\n",
      "Iteration 41, inertia 93202.030\n",
      "Iteration 42, inertia 93201.956\n",
      "Iteration 43, inertia 93201.862\n",
      "Iteration 44, inertia 93201.751\n",
      "Iteration 45, inertia 93201.658\n",
      "Iteration 46, inertia 93201.572\n",
      "Iteration 47, inertia 93201.505\n",
      "Iteration 48, inertia 93201.429\n",
      "Iteration 49, inertia 93201.363\n",
      "Iteration 50, inertia 93201.317\n",
      "Iteration 51, inertia 93201.283\n",
      "Iteration 52, inertia 93201.257\n",
      "Iteration 53, inertia 93201.235\n",
      "Iteration 54, inertia 93201.215\n",
      "Iteration 55, inertia 93201.196\n",
      "Iteration 56, inertia 93201.178\n",
      "Iteration 57, inertia 93201.159\n",
      "Iteration 58, inertia 93201.132\n",
      "Iteration 59, inertia 93201.116\n",
      "Iteration 60, inertia 93201.100\n",
      "Iteration 61, inertia 93201.086\n",
      "Iteration 62, inertia 93201.077\n",
      "Iteration 63, inertia 93201.068\n",
      "Iteration 64, inertia 93201.061\n",
      "Iteration 65, inertia 93201.053\n",
      "Iteration 66, inertia 93201.045\n",
      "Iteration 67, inertia 93201.038\n",
      "Iteration 68, inertia 93201.028\n",
      "Iteration 69, inertia 93201.018\n",
      "Iteration 70, inertia 93201.009\n",
      "Iteration 71, inertia 93201.002\n",
      "Iteration 72, inertia 93200.992\n",
      "Iteration 73, inertia 93200.984\n",
      "Iteration 74, inertia 93200.973\n",
      "Iteration 75, inertia 93200.963\n",
      "Iteration 76, inertia 93200.956\n",
      "Iteration 77, inertia 93200.951\n",
      "Iteration 78, inertia 93200.948\n",
      "Iteration 79, inertia 93200.945\n",
      "Iteration 80, inertia 93200.943\n",
      "Iteration 81, inertia 93200.942\n",
      "Iteration 82, inertia 93200.940\n",
      "Iteration 83, inertia 93200.939\n",
      "Iteration 84, inertia 93200.939\n",
      "Iteration 85, inertia 93200.938\n",
      "Iteration 86, inertia 93200.936\n",
      "Iteration 87, inertia 93200.935\n",
      "Iteration 88, inertia 93200.935\n",
      "Iteration 89, inertia 93200.934\n",
      "Iteration 90, inertia 93200.934\n",
      "Iteration 91, inertia 93200.934\n",
      "Converged at iteration 91: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans8= cluster_texts(8, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  9 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 181983.493\n",
      "Iteration  1, inertia 93771.841\n",
      "Iteration  2, inertia 93355.062\n",
      "Iteration  3, inertia 93267.022\n",
      "Iteration  4, inertia 93241.009\n",
      "Iteration  5, inertia 93228.513\n",
      "Iteration  6, inertia 93218.177\n",
      "Iteration  7, inertia 93206.260\n",
      "Iteration  8, inertia 93198.028\n",
      "Iteration  9, inertia 93193.134\n",
      "Iteration 10, inertia 93190.658\n",
      "Iteration 11, inertia 93189.185\n",
      "Iteration 12, inertia 93188.179\n",
      "Iteration 13, inertia 93187.276\n",
      "Iteration 14, inertia 93186.491\n",
      "Iteration 15, inertia 93185.701\n",
      "Iteration 16, inertia 93184.458\n",
      "Iteration 17, inertia 93182.964\n",
      "Iteration 18, inertia 93180.671\n",
      "Iteration 19, inertia 93177.406\n",
      "Iteration 20, inertia 93173.770\n",
      "Iteration 21, inertia 93168.660\n",
      "Iteration 22, inertia 93162.855\n",
      "Iteration 23, inertia 93156.551\n",
      "Iteration 24, inertia 93151.150\n",
      "Iteration 25, inertia 93146.688\n",
      "Iteration 26, inertia 93142.516\n",
      "Iteration 27, inertia 93138.930\n",
      "Iteration 28, inertia 93136.440\n",
      "Iteration 29, inertia 93134.985\n",
      "Iteration 30, inertia 93133.233\n",
      "Iteration 31, inertia 93132.239\n",
      "Iteration 32, inertia 93131.397\n",
      "Iteration 33, inertia 93130.634\n",
      "Iteration 34, inertia 93129.876\n",
      "Iteration 35, inertia 93129.002\n",
      "Iteration 36, inertia 93128.048\n",
      "Iteration 37, inertia 93126.874\n",
      "Iteration 38, inertia 93125.645\n",
      "Iteration 39, inertia 93124.338\n",
      "Iteration 40, inertia 93122.954\n",
      "Iteration 41, inertia 93121.513\n",
      "Iteration 42, inertia 93119.806\n",
      "Iteration 43, inertia 93117.823\n",
      "Iteration 44, inertia 93115.965\n",
      "Iteration 45, inertia 93114.538\n",
      "Iteration 46, inertia 93113.635\n",
      "Iteration 47, inertia 93113.055\n",
      "Iteration 48, inertia 93112.666\n",
      "Iteration 49, inertia 93112.473\n",
      "Iteration 50, inertia 93112.368\n",
      "Iteration 51, inertia 93112.291\n",
      "Iteration 52, inertia 93112.224\n",
      "Iteration 53, inertia 93112.175\n",
      "Iteration 54, inertia 93112.136\n",
      "Iteration 55, inertia 93112.106\n",
      "Iteration 56, inertia 93112.090\n",
      "Iteration 57, inertia 93112.079\n",
      "Iteration 58, inertia 93112.065\n",
      "Iteration 59, inertia 93112.051\n",
      "Iteration 60, inertia 93112.041\n",
      "Iteration 61, inertia 93112.027\n",
      "Iteration 62, inertia 93112.015\n",
      "Iteration 63, inertia 93112.006\n",
      "Iteration 64, inertia 93111.995\n",
      "Iteration 65, inertia 93111.986\n",
      "Iteration 66, inertia 93111.979\n",
      "Iteration 67, inertia 93111.973\n",
      "Iteration 68, inertia 93111.967\n",
      "Iteration 69, inertia 93111.961\n",
      "Iteration 70, inertia 93111.955\n",
      "Iteration 71, inertia 93111.949\n",
      "Iteration 72, inertia 93111.944\n",
      "Iteration 73, inertia 93111.938\n",
      "Iteration 74, inertia 93111.936\n",
      "Iteration 75, inertia 93111.934\n",
      "Iteration 76, inertia 93111.931\n",
      "Iteration 77, inertia 93111.929\n",
      "Iteration 78, inertia 93111.927\n",
      "Iteration 79, inertia 93111.926\n",
      "Iteration 80, inertia 93111.923\n",
      "Iteration 81, inertia 93111.920\n",
      "Iteration 82, inertia 93111.916\n",
      "Iteration 83, inertia 93111.912\n",
      "Iteration 84, inertia 93111.910\n",
      "Iteration 85, inertia 93111.908\n",
      "Iteration 86, inertia 93111.906\n",
      "Iteration 87, inertia 93111.905\n",
      "Iteration 88, inertia 93111.904\n",
      "Iteration 89, inertia 93111.903\n",
      "Iteration 90, inertia 93111.903\n",
      "Converged at iteration 90: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans9= cluster_texts(9, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  10 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 180788.896\n",
      "Iteration  1, inertia 93700.153\n",
      "Iteration  2, inertia 93398.157\n",
      "Iteration  3, inertia 93273.996\n",
      "Iteration  4, inertia 93197.660\n",
      "Iteration  5, inertia 93146.223\n",
      "Iteration  6, inertia 93088.761\n",
      "Iteration  7, inertia 93043.641\n",
      "Iteration  8, inertia 93030.912\n",
      "Iteration  9, inertia 93021.742\n",
      "Iteration 10, inertia 93007.681\n",
      "Iteration 11, inertia 92991.070\n",
      "Iteration 12, inertia 92979.084\n",
      "Iteration 13, inertia 92970.768\n",
      "Iteration 14, inertia 92964.771\n",
      "Iteration 15, inertia 92960.661\n",
      "Iteration 16, inertia 92956.838\n",
      "Iteration 17, inertia 92952.473\n",
      "Iteration 18, inertia 92947.638\n",
      "Iteration 19, inertia 92942.819\n",
      "Iteration 20, inertia 92938.672\n",
      "Iteration 21, inertia 92936.422\n",
      "Iteration 22, inertia 92935.895\n",
      "Iteration 23, inertia 92935.813\n",
      "Iteration 24, inertia 92935.776\n",
      "Iteration 25, inertia 92935.759\n",
      "Iteration 26, inertia 92935.748\n",
      "Iteration 27, inertia 92935.743\n",
      "Iteration 28, inertia 92935.739\n",
      "Iteration 29, inertia 92935.736\n",
      "Iteration 30, inertia 92935.735\n",
      "Iteration 31, inertia 92935.734\n",
      "Iteration 32, inertia 92935.733\n",
      "Iteration 33, inertia 92935.733\n",
      "Iteration 34, inertia 92935.733\n",
      "Iteration 35, inertia 92935.733\n",
      "Iteration 36, inertia 92935.732\n",
      "Iteration 37, inertia 92935.732\n",
      "Iteration 38, inertia 92935.731\n",
      "Iteration 39, inertia 92935.731\n",
      "Iteration 40, inertia 92935.731\n",
      "Converged at iteration 40: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans10= cluster_texts(10, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  11 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 181002.707\n",
      "Iteration  1, inertia 93664.278\n",
      "Iteration  2, inertia 93336.676\n",
      "Iteration  3, inertia 93228.509\n",
      "Iteration  4, inertia 93167.443\n",
      "Iteration  5, inertia 93118.252\n",
      "Iteration  6, inertia 93076.728\n",
      "Iteration  7, inertia 93028.586\n",
      "Iteration  8, inertia 92999.662\n",
      "Iteration  9, inertia 92983.819\n",
      "Iteration 10, inertia 92973.506\n",
      "Iteration 11, inertia 92966.601\n",
      "Iteration 12, inertia 92961.224\n",
      "Iteration 13, inertia 92957.842\n",
      "Iteration 14, inertia 92955.677\n",
      "Iteration 15, inertia 92954.239\n",
      "Iteration 16, inertia 92952.922\n",
      "Iteration 17, inertia 92951.884\n",
      "Iteration 18, inertia 92951.260\n",
      "Iteration 19, inertia 92950.577\n",
      "Iteration 20, inertia 92949.906\n",
      "Iteration 21, inertia 92949.148\n",
      "Iteration 22, inertia 92948.153\n",
      "Iteration 23, inertia 92946.812\n",
      "Iteration 24, inertia 92944.338\n",
      "Iteration 25, inertia 92938.884\n",
      "Iteration 26, inertia 92929.136\n",
      "Iteration 27, inertia 92917.510\n",
      "Iteration 28, inertia 92908.654\n",
      "Iteration 29, inertia 92903.519\n",
      "Iteration 30, inertia 92900.846\n",
      "Iteration 31, inertia 92898.726\n",
      "Iteration 32, inertia 92897.049\n",
      "Iteration 33, inertia 92895.917\n",
      "Iteration 34, inertia 92895.067\n",
      "Iteration 35, inertia 92894.468\n",
      "Iteration 36, inertia 92893.987\n",
      "Iteration 37, inertia 92893.572\n",
      "Iteration 38, inertia 92893.227\n",
      "Iteration 39, inertia 92892.917\n",
      "Iteration 40, inertia 92892.644\n",
      "Iteration 41, inertia 92892.441\n",
      "Iteration 42, inertia 92892.264\n",
      "Iteration 43, inertia 92892.125\n",
      "Iteration 44, inertia 92892.018\n",
      "Iteration 45, inertia 92891.945\n",
      "Iteration 46, inertia 92891.889\n",
      "Iteration 47, inertia 92891.840\n",
      "Iteration 48, inertia 92891.806\n",
      "Iteration 49, inertia 92891.780\n",
      "Iteration 50, inertia 92891.765\n",
      "Iteration 51, inertia 92891.756\n",
      "Iteration 52, inertia 92891.751\n",
      "Iteration 53, inertia 92891.749\n",
      "Iteration 54, inertia 92891.747\n",
      "Iteration 55, inertia 92891.745\n",
      "Iteration 56, inertia 92891.744\n",
      "Iteration 57, inertia 92891.743\n",
      "Iteration 58, inertia 92891.742\n",
      "Iteration 59, inertia 92891.740\n",
      "Iteration 60, inertia 92891.735\n",
      "Iteration 61, inertia 92891.732\n",
      "Iteration 62, inertia 92891.729\n",
      "Iteration 63, inertia 92891.727\n",
      "Iteration 64, inertia 92891.726\n",
      "Iteration 65, inertia 92891.725\n",
      "Iteration 66, inertia 92891.724\n",
      "Iteration 67, inertia 92891.724\n",
      "Iteration 68, inertia 92891.723\n",
      "Iteration 69, inertia 92891.722\n",
      "Iteration 70, inertia 92891.722\n",
      "Iteration 71, inertia 92891.721\n",
      "Iteration 72, inertia 92891.721\n",
      "Converged at iteration 72: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans11= cluster_texts(11, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning KMeans Clustering, number of clusters =  12 \n",
      "\n",
      "Initialization complete\n",
      "Iteration  0, inertia 180397.402\n",
      "Iteration  1, inertia 93703.946\n",
      "Iteration  2, inertia 93268.502\n",
      "Iteration  3, inertia 93103.217\n",
      "Iteration  4, inertia 92984.758\n",
      "Iteration  5, inertia 92884.436\n",
      "Iteration  6, inertia 92848.951\n",
      "Iteration  7, inertia 92841.731\n",
      "Iteration  8, inertia 92837.937\n",
      "Iteration  9, inertia 92834.947\n",
      "Iteration 10, inertia 92832.361\n",
      "Iteration 11, inertia 92830.079\n",
      "Iteration 12, inertia 92827.424\n",
      "Iteration 13, inertia 92823.431\n",
      "Iteration 14, inertia 92817.678\n",
      "Iteration 15, inertia 92812.365\n",
      "Iteration 16, inertia 92808.479\n",
      "Iteration 17, inertia 92805.286\n",
      "Iteration 18, inertia 92803.095\n",
      "Iteration 19, inertia 92800.855\n",
      "Iteration 20, inertia 92798.761\n",
      "Iteration 21, inertia 92796.542\n",
      "Iteration 22, inertia 92794.564\n",
      "Iteration 23, inertia 92792.805\n",
      "Iteration 24, inertia 92791.114\n",
      "Iteration 25, inertia 92789.411\n",
      "Iteration 26, inertia 92787.509\n",
      "Iteration 27, inertia 92786.011\n",
      "Iteration 28, inertia 92784.613\n",
      "Iteration 29, inertia 92783.544\n",
      "Iteration 30, inertia 92782.460\n",
      "Iteration 31, inertia 92781.696\n",
      "Iteration 32, inertia 92781.090\n",
      "Iteration 33, inertia 92780.666\n",
      "Iteration 34, inertia 92780.433\n",
      "Iteration 35, inertia 92780.296\n",
      "Iteration 36, inertia 92780.186\n",
      "Iteration 37, inertia 92780.075\n",
      "Iteration 38, inertia 92780.031\n",
      "Iteration 39, inertia 92779.982\n",
      "Iteration 40, inertia 92779.942\n",
      "Iteration 41, inertia 92779.910\n",
      "Iteration 42, inertia 92779.885\n",
      "Iteration 43, inertia 92779.867\n",
      "Iteration 44, inertia 92779.852\n",
      "Iteration 45, inertia 92779.841\n",
      "Iteration 46, inertia 92779.834\n",
      "Iteration 47, inertia 92779.828\n",
      "Iteration 48, inertia 92779.823\n",
      "Iteration 49, inertia 92779.818\n",
      "Iteration 50, inertia 92779.814\n",
      "Iteration 51, inertia 92779.811\n",
      "Iteration 52, inertia 92779.809\n",
      "Iteration 53, inertia 92779.807\n",
      "Iteration 54, inertia 92779.805\n",
      "Iteration 55, inertia 92779.802\n",
      "Iteration 56, inertia 92779.800\n",
      "Iteration 57, inertia 92779.798\n",
      "Iteration 58, inertia 92779.797\n",
      "Iteration 59, inertia 92779.795\n",
      "Iteration 60, inertia 92779.794\n",
      "Iteration 61, inertia 92779.793\n",
      "Iteration 62, inertia 92779.793\n",
      "Iteration 63, inertia 92779.792\n",
      "Iteration 64, inertia 92779.792\n",
      "Iteration 65, inertia 92779.791\n",
      "Iteration 66, inertia 92779.791\n",
      "Converged at iteration 66: center shift 0.000000e+00 within tolerance 1.097946e-09\n"
     ]
    }
   ],
   "source": [
    "kmeans12= cluster_texts(12, documents_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [kmeans3, kmeans4, kmeans5, kmeans6, kmeans7, kmeans8, kmeans9, kmeans10, kmeans11, kmeans12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans3.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in k_list:\n",
    "    labels = i.labels_\n",
    "    kmeans_df[i] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df.columns = ['kmeans3', 'kmeans4', 'kmeans5', 'kmeans6', 'kmeans7', 'kmeans8', 'kmeans9', 'kmeans10', 'kmeans11', 'kmeans12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df['stemmed'] = df['stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95790, 11)\n",
      "(95790, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(kmeans_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmeans3</th>\n",
       "      <th>kmeans4</th>\n",
       "      <th>kmeans5</th>\n",
       "      <th>kmeans6</th>\n",
       "      <th>kmeans7</th>\n",
       "      <th>kmeans8</th>\n",
       "      <th>kmeans9</th>\n",
       "      <th>kmeans10</th>\n",
       "      <th>kmeans11</th>\n",
       "      <th>kmeans12</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>never showtim new seri reviv spoiler ahead epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>alphago victori defeat human opportun loss hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>weapon war becam weapon web everi year artist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>geniu quietli laid bunch engin surviv media co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>insid test flight facebook first internet dron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kmeans3  kmeans4  kmeans5  kmeans6  kmeans7  kmeans8  kmeans9  kmeans10  \\\n",
       "0        0        0        1        0        6        4        6         8   \n",
       "1        0        0        1        0        6        4        6         8   \n",
       "2        0        0        1        0        6        4        2         3   \n",
       "3        0        1        2        0        5        1        4         9   \n",
       "4        0        0        1        0        6        4        2         3   \n",
       "\n",
       "   kmeans11  kmeans12                                            stemmed  \n",
       "0         9         8  never showtim new seri reviv spoiler ahead epi...  \n",
       "1         9         8  alphago victori defeat human opportun loss hum...  \n",
       "2         9        10  weapon war becam weapon web everi year artist ...  \n",
       "3         5         2  geniu quietli laid bunch engin surviv media co...  \n",
       "4         9        10  insid test flight facebook first internet dron...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKPOINT --- SAVE TO CSV TO AVOID RUNNING KMEANS FUNCTIONS AGAIN\n",
    "kmeans_df.to_csv('kmeans_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = km.labels_.tolist()\n",
    "    pred = km.labels_\n",
    "    score = calinski_harabaz_score(km, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_score = []\n",
    "\n",
    "for i in k_list:\n",
    "    pred = i.labels_\n",
    "    score = calinski_harabaz_score(X_2, pred)\n",
    "    CH_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([3, 4, 5, 6, 7], CH_score)\n",
    "plt.xticks([3,4,5,6,7])\n",
    "plt.title(\"Calinski Harabaz Scores for Different Values of K\")\n",
    "plt.ylabel(\"Variance Ratio\")\n",
    "plt.xlabel(\"K=\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check Clusters for K's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    55197\n",
       "1    20409\n",
       "2    20184\n",
       "Name: kmeans3, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_df['kmeans3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47367\n",
       "4    25039\n",
       "5    13712\n",
       "1     4468\n",
       "3     4243\n",
       "2      961\n",
       "Name: kmeans6, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_df['kmeans6'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, ..., 1, 11,\n",
       "        'nuclear-tip missil hurtl toward unit state would abl stop mayb lucki expert warn unit state missil defens system reliabl peopl might think right constel sensor 36 interceptor missil make ground-bas midcours defens system gmd intend act insur small-scal nuclear attack north korea possibl iran accord depart defens neither countri missil capabl reach us although us offici say north korea get'],\n",
       "       [1, 2, 3, ..., 1, 11,\n",
       "        'donald trump offici presid unit state complet control america nuclear arsen decid start nuclear war legal safeguard stop instead much less tangibl web norm taboo fear rein us presid sinc world war ii north korea escal nuclear weapon test russia promis strengthen nuclear forc new presid unit state openli tweet us must strengthen expand nuclear capabl expert worri fragil web'],\n",
       "       [1, 2, 3, ..., 1, 11,\n",
       "        \"despit effort last three american presid north korea continu advanc nuclear state donald trump rein rogu state better 'in televis new year day address nation north korean leader kim jong un\\\\xa0announc resolve\\\\xa0to develop missil capabl reach u. mainland continu build self-defens capabl pivot nuclear forc capabl preemptiv strike said `` president-elect trump respond next day twitter north korea state final stage\"],\n",
       "       ...,\n",
       "       [1, 2, 3, ..., 1, 11,\n",
       "        'want get brief email sign-up good morn surpris visit beij pressur mount moscow cosmet surgeon special fish need know intern debut north korea leader kim jong-un met secretli presid xi jinp china beij surpris discuss came week plan summit meet american south korean leader mr. kim first trip outsid north korea sinc take power six year ago add anoth layer complex rush diplomaci around north korea nuclear weapon program'],\n",
       "       [1, 2, 3, ..., 1, 11,\n",
       "        'seoul south korea north korea reclus leader kim jong-un extend extrem rare invit foreign head state saturday use diplomat open creat olymp south korea ask leader presid moon jae-in visit north summit meet mr. kim unusu invit receiv mr. moon caution optim latest sign warm relat two rival govern except tens period north nuclear weapon program overtur north also risk drive wedg south'],\n",
       "       [1, 2, 3, ..., 1, 11,\n",
       "        'month washington brace north korea test intercontinent ballist missil wait see close could get unit state aggress presid trump react look kim jong-un north 33-year-old leader differ plan one intend improv abil strike unit state without set american militari respons instead go distanc step test missil fli high space sunday one reach height 1,300 mile']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_df.loc[kmeans_df['kmeans6'] == 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
